{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92e48866",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25791a74",
   "metadata": {},
   "source": [
    "#### Import Data and Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b080dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45079ad",
   "metadata": {},
   "source": [
    "#### Import the CSV Data as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e11c6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/heart.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20634923",
   "metadata": {},
   "source": [
    "#### Show Top 5 Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7e412a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd32281",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "56d72fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['output'], axis=1).values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "924b7f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['output'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0656b4c",
   "metadata": {},
   "source": [
    "#### Separate Dataset into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed5c4e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 13), (61, 13), (242,), (61,))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8022a6b2",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f144fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd80317",
   "metadata": {},
   "source": [
    "#### Create an Evaluate Function to give all metrics after model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c247bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    return accuracy, precision, recall, f1, conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "70c5ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": xgb.XGBClassifier(random_state=42),\n",
    "    \"Support Vector Machine (SVM)\": SVC(),\n",
    "    \"K-Nearest Neighbors (KNN)\": KNeighborsClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),  \n",
    "    \"Neural Network (MLP)\": MLPClassifier(tol=1e-3, max_iter=500, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(algorithm='SAMME', random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "697d62e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Logistic Regression...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic Regression: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Tuning Decision Tree...\n",
      "Best parameters for Decision Tree: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "\n",
      "Tuning Random Forest...\n",
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "\n",
      "Tuning Gradient Boosting...\n",
      "Best parameters for Gradient Boosting: {'learning_rate': 0.05, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Tuning XGBoost...\n",
      "Best parameters for XGBoost: {'learning_rate': 0.05, 'max_depth': 7, 'n_estimators': 100, 'subsample': 0.8}\n",
      "\n",
      "Tuning Support Vector Machine (SVM)...\n",
      "Best parameters for Support Vector Machine (SVM): {'C': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "\n",
      "Tuning K-Nearest Neighbors (KNN)...\n",
      "Best parameters for K-Nearest Neighbors (KNN): {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'uniform'}\n",
      "\n",
      "Tuning Naive Bayes...\n",
      "Tuning Neural Network (MLP)...\n",
      "Best parameters for Neural Network (MLP): {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "\n",
      "Tuning AdaBoost...\n",
      "Best parameters for AdaBoost: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "\n",
      "Tuning Extra Trees...\n",
      "Best parameters for Extra Trees: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.05],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.05],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    },\n",
    "\n",
    "    \"Support Vector Machine (SVM)\": {\n",
    "        'C': [0.1, 1, 3, 10, 100],\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    \"K-Nearest Neighbors (KNN)\": {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    \"Naive Bayes\": {},  # GaussianNB has no hyperparameters to tune\n",
    "    \"Neural Network (MLP)\": {\n",
    "        'hidden_layer_sizes': [(50,), (100,)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'learning_rate': ['constant', 'adaptive']\n",
    "    },\n",
    "    \"AdaBoost\": {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'learning_rate': [0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    \"Extra Trees\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Loop through each model and apply GridSearchCV or RandomizedSearchCV\n",
    "best_estimators = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Tuning {model_name}...\")\n",
    "    param_grid = param_grids.get(model_name, {})\n",
    "    \n",
    "    search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, scoring='accuracy') if param_grid else None\n",
    "    \n",
    "    if search:\n",
    "        search.fit(X_train, y_train)  \n",
    "        best_estimators[model_name] = search.best_estimator_\n",
    "        print(f\"Best parameters for {model_name}: {search.best_params_}\\n\")\n",
    "        \n",
    "    else:\n",
    "        # If no parameters to tune, use the default model\n",
    "        model.fit(X_train, y_train)\n",
    "        best_estimators[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e9b5553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogistic Regression:\u001b[0m\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8223\n",
      "- Precision: 0.8039\n",
      "- Recall: 0.9044\n",
      "- F1 Score: 0.8512\n",
      "- Confusion Matrix:\n",
      " [[ 76  30]\n",
      " [ 13 123]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8689\n",
      "- Precision: 0.8000\n",
      "- Recall: 0.9655\n",
      "- F1 Score: 0.8750\n",
      "- Confusion Matrix:\n",
      " [[25  7]\n",
      " [ 1 28]]\n",
      "===================================\n",
      "\n",
      "\n",
      "\u001b[1mDecision Tree:\u001b[0m\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9339\n",
      "- Precision: 0.9412\n",
      "- Recall: 0.9412\n",
      "- F1 Score: 0.9412\n",
      "- Confusion Matrix:\n",
      " [[ 98   8]\n",
      " [  8 128]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8197\n",
      "- Precision: 0.7500\n",
      "- Recall: 0.9310\n",
      "- F1 Score: 0.8308\n",
      "- Confusion Matrix:\n",
      " [[23  9]\n",
      " [ 2 27]]\n",
      "===================================\n",
      "\n",
      "\n",
      "\u001b[1mRandom Forest:\u001b[0m\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9339\n",
      "- Precision: 0.9348\n",
      "- Recall: 0.9485\n",
      "- F1 Score: 0.9416\n",
      "- Confusion Matrix:\n",
      " [[ 97   9]\n",
      " [  7 129]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9016\n",
      "- Precision: 0.8286\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 0.9062\n",
      "- Confusion Matrix:\n",
      " [[26  6]\n",
      " [ 0 29]]\n",
      "===================================\n",
      "\n",
      "\n",
      "\u001b[1mGradient Boosting:\u001b[0m\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 1.0000\n",
      "- Confusion Matrix:\n",
      " [[106   0]\n",
      " [  0 136]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8852\n",
      "- Precision: 0.8235\n",
      "- Recall: 0.9655\n",
      "- F1 Score: 0.8889\n",
      "- Confusion Matrix:\n",
      " [[26  6]\n",
      " [ 1 28]]\n",
      "===================================\n",
      "\n",
      "\n",
      "\u001b[1mXGBoost:\u001b[0m\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9917\n",
      "- Precision: 0.9926\n",
      "- Recall: 0.9926\n",
      "- F1 Score: 0.9926\n",
      "- Confusion Matrix:\n",
      " [[105   1]\n",
      " [  1 135]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8689\n",
      "- Precision: 0.7838\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 0.8788\n",
      "- Confusion Matrix:\n",
      " [[24  8]\n",
      " [ 0 29]]\n",
      "===================================\n",
      "\n",
      "\n",
      "\u001b[1mSupport Vector Machine (SVM):\u001b[0m\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8223\n",
      "- Precision: 0.7888\n",
      "- Recall: 0.9338\n",
      "- F1 Score: 0.8552\n",
      "- Confusion Matrix:\n",
      " [[ 72  34]\n",
      " [  9 127]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8689\n",
      "- Precision: 0.7838\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 0.8788\n",
      "- Confusion Matrix:\n",
      " [[24  8]\n",
      " [ 0 29]]\n",
      "===================================\n",
      "\n",
      "\n",
      "\u001b[1mK-Nearest Neighbors (KNN):\u001b[0m\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8595\n",
      "- Precision: 0.8592\n",
      "- Recall: 0.8971\n",
      "- F1 Score: 0.8777\n",
      "- Confusion Matrix:\n",
      " [[ 86  20]\n",
      " [ 14 122]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8689\n",
      "- Precision: 0.7838\n",
      "- Recall: 1.0000\n",
      "- F1 Score: 0.8788\n",
      "- Confusion Matrix:\n",
      " [[24  8]\n",
      " [ 0 29]]\n",
      "===================================\n",
      "\n",
      "\n",
      "\u001b[1mNaive Bayes:\u001b[0m\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8182\n",
      "- Precision: 0.8239\n",
      "- Recall: 0.8603\n",
      "- F1 Score: 0.8417\n",
      "- Confusion Matrix:\n",
      " [[ 81  25]\n",
      " [ 19 117]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8852\n",
      "- Precision: 0.8667\n",
      "- Recall: 0.8966\n",
      "- F1 Score: 0.8814\n",
      "- Confusion Matrix:\n",
      " [[28  4]\n",
      " [ 3 26]]\n",
      "===================================\n",
      "\n",
      "\n",
      "\u001b[1mNeural Network (MLP):\u001b[0m\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8264\n",
      "- Precision: 0.8219\n",
      "- Recall: 0.8824\n",
      "- F1 Score: 0.8511\n",
      "- Confusion Matrix:\n",
      " [[ 80  26]\n",
      " [ 16 120]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9016\n",
      "- Precision: 0.8485\n",
      "- Recall: 0.9655\n",
      "- F1 Score: 0.9032\n",
      "- Confusion Matrix:\n",
      " [[27  5]\n",
      " [ 1 28]]\n",
      "===================================\n",
      "\n",
      "\n",
      "\u001b[1mAdaBoost:\u001b[0m\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8512\n",
      "- Precision: 0.8425\n",
      "- Recall: 0.9044\n",
      "- F1 Score: 0.8723\n",
      "- Confusion Matrix:\n",
      " [[ 83  23]\n",
      " [ 13 123]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9180\n",
      "- Precision: 0.8750\n",
      "- Recall: 0.9655\n",
      "- F1 Score: 0.9180\n",
      "- Confusion Matrix:\n",
      " [[28  4]\n",
      " [ 1 28]]\n",
      "===================================\n",
      "\n",
      "\n",
      "\u001b[1mExtra Trees:\u001b[0m\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9421\n",
      "- Precision: 0.9357\n",
      "- Recall: 0.9632\n",
      "- F1 Score: 0.9493\n",
      "- Confusion Matrix:\n",
      " [[ 97   9]\n",
      " [  5 131]]\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8852\n",
      "- Precision: 0.8235\n",
      "- Recall: 0.9655\n",
      "- F1 Score: 0.8889\n",
      "- Confusion Matrix:\n",
      " [[26  6]\n",
      " [ 1 28]]\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store evaluation results\n",
    "results = {}\n",
    "\n",
    "BOLD = '\\033[1m'\n",
    "RESET = '\\033[0m'  \n",
    "\n",
    "# Train each best estimator and evaluate\n",
    "for model_name, model in best_estimators.items():\n",
    "    print(f\"{BOLD}{model_name}:{RESET}\")\n",
    "\n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on both train and test sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate performance on training data\n",
    "    train_accuracy, train_precision, train_recall, train_f1, train_conf_matrix = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    # Evaluate performance on testing data\n",
    "    test_accuracy, test_precision, test_recall, test_f1, test_conf_matrix = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    # Store results\n",
    "    results[model_name] = {\n",
    "        \"Train\": {\n",
    "            \"Accuracy\": train_accuracy,\n",
    "            \"Precision\": train_precision,\n",
    "            \"Recall\": train_recall,\n",
    "            \"F1 Score\": train_f1,\n",
    "            \"Confusion Matrix\": train_conf_matrix\n",
    "        },\n",
    "        \"Test\": {\n",
    "            \"Accuracy\": test_accuracy,\n",
    "            \"Precision\": test_precision,\n",
    "            \"Recall\": test_recall,\n",
    "            \"F1 Score\": test_f1,\n",
    "            \"Confusion Matrix\": test_conf_matrix\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Print results for each model\n",
    "    print(\"Model performance for Training set\")\n",
    "    print(f\"- Accuracy: {train_accuracy:.4f}\") \n",
    "    print(f\"- Precision: {train_precision:.4f}\")\n",
    "    print(f\"- Recall: {train_recall:.4f}\")\n",
    "    print(f\"- F1 Score: {train_f1:.4f}\")\n",
    "    print(\"- Confusion Matrix:\\n\", train_conf_matrix)\n",
    "\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print(\"Model performance for Test set\")\n",
    "    print(f\"- Accuracy: {test_accuracy:.4f}\") \n",
    "    print(f\"- Precision: {test_precision:.4f}\")\n",
    "    print(f\"- Recall: {test_recall:.4f}\")\n",
    "    print(f\"- F1 Score: {test_f1:.4f}\")\n",
    "    print(\"- Confusion Matrix:\\n\", test_conf_matrix)\n",
    "\n",
    "    print(\"=\"*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb4917f",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b267775a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Test Set Performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.830769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machine (SVM)</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbors (KNN)</th>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.881356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network (MLP)</th>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.918033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Extra Trees</th>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Accuracy  Precision    Recall  F1 Score\n",
       "Logistic Regression           0.868852   0.800000  0.965517  0.875000\n",
       "Decision Tree                 0.819672   0.750000  0.931034  0.830769\n",
       "Random Forest                 0.901639   0.828571  1.000000  0.906250\n",
       "Gradient Boosting             0.885246   0.823529  0.965517  0.888889\n",
       "XGBoost                       0.868852   0.783784  1.000000  0.878788\n",
       "Support Vector Machine (SVM)  0.868852   0.783784  1.000000  0.878788\n",
       "K-Nearest Neighbors (KNN)     0.868852   0.783784  1.000000  0.878788\n",
       "Naive Bayes                   0.885246   0.866667  0.896552  0.881356\n",
       "Neural Network (MLP)          0.901639   0.848485  0.965517  0.903226\n",
       "AdaBoost                      0.918033   0.875000  0.965517  0.918033\n",
       "Extra Trees                   0.885246   0.823529  0.965517  0.888889"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({model: {metric: results[model][\"Test\"][metric] for metric in [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]} for model in results.keys()})\n",
    "print(\"\\nSummary of Test Set Performance:\")\n",
    "display(results_df.transpose())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
